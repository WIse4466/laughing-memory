{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "160fa193-aac2-4f6d-93af-5b2fdd8b31a3",
      "metadata": {
        "id": "160fa193-aac2-4f6d-93af-5b2fdd8b31a3"
      },
      "source": [
        "# **Create Data for Social Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b7be4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.oauth2 import service_account\n",
        "from google.cloud import bigquery\n",
        "from google.cloud.exceptions import NotFound\n",
        "import pandas as pd\n",
        "from google.cloud import storage\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35845a99",
      "metadata": {},
      "outputs": [],
      "source": [
        "project_id = \"looker-assignment-113356033\"\n",
        "dataset_id = \"final_project_dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5d98958",
      "metadata": {},
      "outputs": [],
      "source": [
        "crendentials = service_account.Credentials.from_service_account_file(r\"C:\\nccu\\workspace\\dataModel_finalProjrct\\looker-assignment-113356033-4959799503ac.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26277df2",
      "metadata": {},
      "outputs": [],
      "source": [
        "bigquery_client = bigquery.Client(project=project_id, credentials=crendentials)\n",
        "storage_client = storage.Client(credentials=crendentials, project=project_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ba22229-a1f3-49b8-a1fc-adc14bd7dd20",
      "metadata": {
        "id": "4ba22229-a1f3-49b8-a1fc-adc14bd7dd20",
        "outputId": "c0e25c93-2668-49ff-b883-ced838722d34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Loaded transform_data/Floki_token_balances.csv: 278628 rows, 5 columns.\n",
            "[INFO] Loaded transform_data/Bonk_token_balances.csv: 39363 rows, 5 columns.\n",
            "[INFO] Loaded transform_data/Mog_token_balances.csv: 144834 rows, 5 columns.\n",
            "[INFO] Loaded transform_data/Shib_token_balances.csv: 5571143 rows, 5 columns.\n",
            "[INFO] Loaded transform_data/PePe_token_balances.csv: 1151498 rows, 5 columns.\n",
            "[INFO] Comparison complete. FLOKI\n",
            "[INFO] Combined data saved to transform_data/FLOKI_compare_holders.csv\n",
            "[INFO] Comparison complete. BONK\n",
            "[INFO] Combined data saved to transform_data/BONK_compare_holders.csv\n",
            "[INFO] Comparison complete. MOG\n",
            "[INFO] Combined data saved to transform_data/MOG_compare_holders.csv\n",
            "[INFO] Comparison complete. SHIB\n",
            "[INFO] Combined data saved to transform_data/SHIB_compare_holders.csv\n",
            "[INFO] Comparison complete. PEPE\n",
            "[INFO] Combined data saved to transform_data/PEPE_compare_holders.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ============================\n",
        "# Compare Two Datasets and Add Indicator Column\n",
        "# ============================\n",
        "\n",
        "def compare_two_datasets(df1, df2, df3, df4, df5, token1='Token1', token2='Token2', token3='Token3', token4='Token4', token5='Token5'):\n",
        "    \"\"\"\n",
        "    Compare two datasets and create a column indicating if an address in the first dataset\n",
        "    also exists in the second dataset.\n",
        "\n",
        "    Args:\n",
        "        df1 (pd.DataFrame): First token dataset.\n",
        "        df2 (pd.DataFrame): Second token dataset.\n",
        "        token1_name (str): Name of the first token.\n",
        "        token2_name (str): Name of the second token.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Updated DataFrame with a new column indicating if an address holds the second token.\n",
        "    \"\"\"\n",
        "    # Add an indicator column for the first dataset\n",
        "    df1[f'Hold {token1}'] = 1\n",
        "\n",
        "    # Extract unique addresses from the second dataset\n",
        "    addresses_in_df2 = set(df2['Address'])\n",
        "    addresses_in_df3 = set(df3['Address'])\n",
        "    addresses_in_df4 = set(df4['Address'])\n",
        "    addresses_in_df5 = set(df5['Address'])\n",
        "\n",
        "    # Add a new column to indicate if the address is also in the second dataset\n",
        "    df1[f'Hold {token2}'] = df1['Address'].apply(\n",
        "        lambda addr: 1 if addr in addresses_in_df2 else 0\n",
        "    )\n",
        "\n",
        "    df1[f'Hold {token3}'] = df1['Address'].apply(\n",
        "        lambda addr: 1 if addr in addresses_in_df3 else 0\n",
        "    )\n",
        "\n",
        "    df1[f'Hold {token4}'] = df1['Address'].apply(\n",
        "        lambda addr: 1 if addr in addresses_in_df4 else 0\n",
        "    )\n",
        "\n",
        "    df1[f'Hold {token5}'] = df1['Address'].apply(\n",
        "        lambda addr: 1 if addr in addresses_in_df5 else 0\n",
        "    )\n",
        "\n",
        "    print(f\"[INFO] Comparison complete. {token1}\")\n",
        "\n",
        "    return df1\n",
        "\n",
        "# Example Usage in Main Function\n",
        "\n",
        "def main():\n",
        "    # Load two specific datasets\n",
        "    Bonk_query = \"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM `looker-assignment-113356033.final_project_dataset.Bonk_token_balances`\n",
        "    \"\"\"\n",
        "\n",
        "    Bonk_balances_data = bigquery_client.query(Bonk_query).to_dataframe()\n",
        "\n",
        "    FLOKI_query = \"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM `looker-assignment-113356033.final_project_dataset.FLOKI_token_balances`\n",
        "    \"\"\"\n",
        "\n",
        "    FLOKI_balances_data = bigquery_client.query(FLOKI_query).to_dataframe()\n",
        "\n",
        "    Mog_query = \"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM `looker-assignment-113356033.final_project_dataset.Mog_token_balances`\n",
        "    \"\"\"\n",
        "\n",
        "    Mog_balances_data = bigquery_client.query(Mog_query).to_dataframe()\n",
        "\n",
        "    Pepe_query = \"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM `looker-assignment-113356033.final_project_dataset.Pepe_token_balances`\n",
        "    \"\"\"\n",
        "\n",
        "    Pepe_balances_data = bigquery_client.query(Pepe_query).to_dataframe()\n",
        "\n",
        "    Shib_query = \"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM `looker-assignment-113356033.final_project_dataset.Shib_token_balances`\n",
        "    \"\"\"\n",
        "\n",
        "    Shib_balances_data = bigquery_client.query(Shib_query).to_dataframe()\n",
        "\n",
        "    df_list = [FLOKI_balances_data, Bonk_balances_data, Mog_balances_data, Shib_balances_data, Pepe_balances_data]\n",
        "    token_names = ['FLOKI', 'BONK', 'MOG', 'SHIB', 'PEPE']\n",
        "\n",
        "    for i in range(5):\n",
        "        # Compare the datasets\n",
        "        comparison_df = compare_two_datasets(df_list[i], df_list[i-1], df_list[i-2], df_list[i-3], df_list[i-4], token_names[i], token_names[i-1], token_names[i-2], token_names[i-3], token_names[i-4])\n",
        "        # Save the result\n",
        "        save_combined_data(comparison_df, f'transform_data/{token_names[i]}_compare_holders.csv')\n",
        "\n",
        "# ============================\n",
        "# 5. Entry Point\n",
        "# ============================\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a47f258-f114-4eef-a93a-790f97aab3f0",
      "metadata": {
        "id": "9a47f258-f114-4eef-a93a-790f97aab3f0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Directory containing the files\n",
        "directory_path = 'transform_data'\n",
        "\n",
        "# List of file names to process\n",
        "file_names = [\n",
        "    'Floki_compare_holders.csv'\n",
        "    #'Bonk_compare_holders.csv'\n",
        "    #'Mog_compare_holders.csv'\n",
        "    #'Shib_compare_holders.csv'\n",
        "    #'Pepe_compare_holders.csv'\n",
        "]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
