{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "002c236f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.oauth2 import service_account\n",
        "from google.cloud import bigquery\n",
        "from google.cloud.exceptions import NotFound\n",
        "import pandas as pd\n",
        "from google.cloud import storage\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9579fc12",
      "metadata": {},
      "outputs": [],
      "source": [
        "project_id = \"looker-assignment-113356033\"\n",
        "dataset_id = \"final_project_dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8659b088",
      "metadata": {},
      "outputs": [],
      "source": [
        "crendentials = service_account.Credentials.from_service_account_file(r\"C:\\nccu\\workspace\\dataModel_finalProjrct\\looker-assignment-113356033-4959799503ac.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "43ae3018",
      "metadata": {},
      "outputs": [],
      "source": [
        "bigquery_client = bigquery.Client(project=project_id, credentials=crendentials)\n",
        "storage_client = storage.Client(credentials=crendentials, project=project_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9e0883f1-4d62-4ac4-8d02-e6acaf353399",
      "metadata": {
        "id": "9e0883f1-4d62-4ac4-8d02-e6acaf353399",
        "outputId": "995ff6a4-4665-473e-9f1f-d1a7c99113cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Found 13 files. Loading...\n",
            "[INFO] Loaded data/Floki\\FLOKI_transfers_part1.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Floki\\FLOKI_transfers_part10.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Floki\\FLOKI_transfers_part11.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Floki\\FLOKI_transfers_part12.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Floki\\FLOKI_transfers_part13.xlsx with 2240 rows and 7 columns.\n",
            "[INFO] Loaded data/Floki\\FLOKI_transfers_part2.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Floki\\FLOKI_transfers_part3.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Floki\\FLOKI_transfers_part4.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Floki\\FLOKI_transfers_part5.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Floki\\FLOKI_transfers_part6.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Floki\\FLOKI_transfers_part7.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Floki\\FLOKI_transfers_part8.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Floki\\FLOKI_transfers_part9.xlsx with 100000 rows and 7 columns.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\wise\\AppData\\Local\\Temp\\ipykernel_10064\\2966295440.py:110: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  df['year_month'] = df[time_column].dt.to_period('M').astype(str)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Transformed 'Block Time' into 'year_month' and 'year_month_day'.\n",
            "[INFO] Combined DataFrame shape: (1202240, 9)\n",
            "[INFO] Calculated balances snapshot for 36 months and 335829 address-month pairs.\n",
            "[INFO] Saved balance data to transform_data/Floki_token_balances.csv. Total rows: 335829\n",
            "[INFO] Found 1 files. Loading...\n",
            "[INFO] Loaded data/Bonk\\Bonk_transfers.xlsx with 166378 rows and 7 columns.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\wise\\AppData\\Local\\Temp\\ipykernel_10064\\2966295440.py:110: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  df['year_month'] = df[time_column].dt.to_period('M').astype(str)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Transformed 'Block Time' into 'year_month' and 'year_month_day'.\n",
            "[INFO] Combined DataFrame shape: (166378, 9)\n",
            "[INFO] Calculated balances snapshot for 23 months and 47745 address-month pairs.\n",
            "[INFO] Saved balance data to transform_data/Bonk_token_balances.csv. Total rows: 47745\n",
            "[INFO] Found 20 files. Loading...\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part1.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part10.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part11.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part12.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part13.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part14.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part15.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part16.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part17.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part18.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part19.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part2.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part20.xlsx with 32980 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part3.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part4.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part5.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part6.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part7.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part8.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Mog\\Mog_transfers_part9.xlsx with 100000 rows and 7 columns.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\wise\\AppData\\Local\\Temp\\ipykernel_10064\\2966295440.py:110: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  df['year_month'] = df[time_column].dt.to_period('M').astype(str)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Transformed 'Block Time' into 'year_month' and 'year_month_day'.\n",
            "[INFO] Combined DataFrame shape: (1932980, 9)\n",
            "[INFO] Calculated balances snapshot for 18 months and 182594 address-month pairs.\n",
            "[INFO] Saved balance data to transform_data/Mog_token_balances.csv. Total rows: 182594\n",
            "[INFO] Found 148 files. Loading...\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part1.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part10.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part100.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part101.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part102.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part103.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part104.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part105.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part106.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part107.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part108.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part109.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part11.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part110.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part111.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part112.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part113.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part114.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part115.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part116.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part117.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part118.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part119.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part12.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part120.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part121.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part122.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part123.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part124.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part125.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part126.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part127.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part128.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part129.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part13.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part130.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part131.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part132.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part133.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part134.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part135.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part136.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part137.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part138.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part139.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part14.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part140.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part141.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part142.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part143.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part144.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part145.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part146.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part147.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part148.xlsx with 73341 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part15.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part16.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part17.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part18.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part19.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part2.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part20.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part21.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part22.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part23.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part24.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part25.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part26.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part27.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part28.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part29.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part3.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part30.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part31.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part32.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part33.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part34.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part35.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part36.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part37.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part38.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part39.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part4.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part40.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part41.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part42.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part43.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part44.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part45.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part46.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part47.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part48.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part49.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part5.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part50.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part51.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part52.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part53.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part54.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part55.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part56.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part57.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part58.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part59.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part6.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part60.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part61.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part62.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part63.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part64.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part65.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part66.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part67.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part68.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part69.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part7.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part70.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part71.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part72.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part73.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part74.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part75.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part76.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part77.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part78.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part79.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part8.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part80.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part81.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part82.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part83.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part84.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part85.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part86.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part87.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part88.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part89.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part9.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part90.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part91.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part92.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part93.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part94.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part95.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part96.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part97.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part98.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Shib\\SHIB_transfers_part99.xlsx with 100000 rows and 7 columns.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\wise\\AppData\\Local\\Temp\\ipykernel_10064\\2966295440.py:110: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  df['year_month'] = df[time_column].dt.to_period('M').astype(str)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Transformed 'Block Time' into 'year_month' and 'year_month_day'.\n",
            "[INFO] Combined DataFrame shape: (14773341, 9)\n",
            "[INFO] Calculated balances snapshot for 54 months and 7520148 address-month pairs.\n",
            "[INFO] Saved balance data to transform_data/Shib_token_balances.csv. Total rows: 7520148\n",
            "[INFO] Found 52 files. Loading...\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part1.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part10.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part11.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part12.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part13.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part14.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part15.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part16.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part17.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part18.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part19.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part2.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part20.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part21.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part22.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part23.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part24.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part25.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part26.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part27.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part28.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part29.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part3.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part30.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part31.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part32.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part33.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part34.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part35.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part36.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part37.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part38.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part39.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part4.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part40.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part41.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part42.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part43.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part44.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part45.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part46.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part47.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part48.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part49.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part5.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part50.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part51.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part52.xlsx with 78110 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part6.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part7.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part8.xlsx with 100000 rows and 7 columns.\n",
            "[INFO] Loaded data/Pepe\\PEPE_transfers_part9.xlsx with 100000 rows and 7 columns.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\wise\\AppData\\Local\\Temp\\ipykernel_10064\\2966295440.py:110: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  df['year_month'] = df[time_column].dt.to_period('M').astype(str)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Transformed 'Block Time' into 'year_month' and 'year_month_day'.\n",
            "[INFO] Combined DataFrame shape: (5178110, 9)\n",
            "[INFO] Calculated balances snapshot for 21 months and 1475375 address-month pairs.\n",
            "[INFO] Saved balance data to transform_data/Pepe_token_balances.csv. Total rows: 1475375\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# 1. Data Loading\n",
        "# ============================\n",
        "Bonk_query = \"\"\"\n",
        "SELECT\n",
        "    Currency Name,\n",
        "    Currency Symbol,\n",
        "    Amount,\n",
        "    Sender,\n",
        "    Receiver,\n",
        "    Block Number,\n",
        "    Block Time\n",
        "FROM `looker-assignment-113356033.final_project_dataset.Bonk_transfer`\n",
        "\"\"\"\n",
        "\n",
        "Bonk_data = bigquery_client.query(Bonk_query).to_dataframe() \n",
        "\n",
        "FLOKI_query_template = \"\"\"\n",
        "SELECT\n",
        "    `Currency Name`,\n",
        "    `Currency Symbol`,\n",
        "    Amount,\n",
        "    Sender,\n",
        "    Receiver,\n",
        "    `Block Number`,\n",
        "    `Block Time`\n",
        "FROM `looker-assignment-113356033.final_project_dataset.FLOKI_transfer_part{part_number}`\n",
        "\"\"\"\n",
        "\n",
        "# 動態生成 UNION ALL 查詢\n",
        "union_queries = []\n",
        "for i in range(1, 11):  # 從 part1 到 part10\n",
        "    union_queries.append(FLOKI_query_template.format(part_number=i))\n",
        "    \n",
        "full_query = \" UNION ALL \".join(union_queries)\n",
        "\n",
        "# 執行一次查詢將所有部分整合到 FLOKI_data\n",
        "FLOKI_data = bigquery_client.query(full_query).to_dataframe()\n",
        "\n",
        "Mog_query_template = \"\"\"\n",
        "SELECT\n",
        "    `Currency Name`,\n",
        "    `Currency Symbol`,\n",
        "    Amount,\n",
        "    Sender,\n",
        "    Receiver,\n",
        "    `Block Number`,\n",
        "    `Block Time`\n",
        "FROM `looker-assignment-113356033.final_project_dataset.Mog_transfer_part{part_number}`\n",
        "\"\"\"\n",
        "\n",
        "# 動態生成 UNION ALL 查詢\n",
        "union_queries = []\n",
        "for i in range(1, 11):  # 從 part1 到 part10\n",
        "    union_queries.append(Mog_query_template.format(part_number=i))\n",
        "    \n",
        "full_query = \" UNION ALL \".join(union_queries)\n",
        "\n",
        "# 執行一次查詢將所有部分整合到 FLOKI_data\n",
        "Mog_data = bigquery_client.query(full_query).to_dataframe()\n",
        "\n",
        "Pepe_query_template = \"\"\"\n",
        "SELECT\n",
        "    `Currency Name`,\n",
        "    `Currency Symbol`,\n",
        "    Amount,\n",
        "    Sender,\n",
        "    Receiver,\n",
        "    `Block Number`,\n",
        "    `Block Time`\n",
        "FROM `looker-assignment-113356033.final_project_dataset.Pepe_transfer_part{part_number}`\n",
        "\"\"\"\n",
        "\n",
        "# 動態生成 UNION ALL 查詢\n",
        "union_queries = []\n",
        "for i in range(1, 11):  # 從 part1 到 part10\n",
        "    union_queries.append(Pepe_query_template.format(part_number=i))\n",
        "    \n",
        "full_query = \" UNION ALL \".join(union_queries)\n",
        "\n",
        "# 執行一次查詢將所有部分整合到 FLOKI_data\n",
        "Pepe_data = bigquery_client.query(full_query).to_dataframe()\n",
        "\n",
        "Shib_query_template = \"\"\"\n",
        "SELECT\n",
        "    `Currency Name`,\n",
        "    `Currency Symbol`,\n",
        "    Amount,\n",
        "    Sender,\n",
        "    Receiver,\n",
        "    `Block Number`,\n",
        "    `Block Time`\n",
        "FROM `looker-assignment-113356033.final_project_dataset.Shib_transfer_part{part_number}`\n",
        "\"\"\"\n",
        "\n",
        "# 動態生成 UNION ALL 查詢\n",
        "union_queries = []\n",
        "for i in range(1, 11):  # 從 part1 到 part10\n",
        "    union_queries.append(Shib_query_template.format(part_number=i))\n",
        "    \n",
        "full_query = \" UNION ALL \".join(union_queries)\n",
        "\n",
        "# 執行一次查詢將所有部分整合到 FLOKI_data\n",
        "Shib_data = bigquery_client.query(full_query).to_dataframe()\n",
        "\n",
        "# ============================\n",
        "# 2. Data Preprocessing\n",
        "# ============================\n",
        "\n",
        "def calculate_balances(transactions_df):\n",
        "    \"\"\"\n",
        "    Calculate net balances for each address based on sent and received transactions,\n",
        "    grouped by year_month to provide snapshots over time.\n",
        "\n",
        "    Args:\n",
        "        transactions_df (pd.DataFrame): DataFrame containing 'Sender', 'Receiver',\n",
        "                                        'Amount', and 'year_month' columns.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame with each address's calculated balance per year_month.\n",
        "    \"\"\"\n",
        "    # Ensure 'Amount' is numeric\n",
        "    transactions_df['Amount'] = pd.to_numeric(transactions_df['Amount'], errors='coerce').fillna(0)\n",
        "\n",
        "    # Ensure 'year_month' column exists\n",
        "    if 'year_month' not in transactions_df.columns:\n",
        "        transactions_df['year_month'] = transactions_df['Block Time'].dt.to_period('M').astype(str)\n",
        "\n",
        "    # Calculate total sent amounts per year_month\n",
        "    sent_df = (\n",
        "        transactions_df\n",
        "        .groupby(['year_month', 'Sender'])['Amount']\n",
        "        .sum()\n",
        "        .reset_index()\n",
        "        .rename(columns={'Sender': 'Address', 'Amount': 'Sent'})\n",
        "    )\n",
        "\n",
        "    # Calculate total received amounts per year_month\n",
        "    received_df = (\n",
        "        transactions_df\n",
        "        .groupby(['year_month', 'Receiver'])['Amount']\n",
        "        .sum()\n",
        "        .reset_index()\n",
        "        .rename(columns={'Receiver': 'Address', 'Amount': 'Received'})\n",
        "    )\n",
        "\n",
        "    # Merge sent and received amounts\n",
        "    balance_df = pd.merge(received_df, sent_df, on=['year_month', 'Address'], how='outer').fillna(0)\n",
        "\n",
        "    # Calculate Net Balance\n",
        "    balance_df['Balance'] = balance_df['Received'] - balance_df['Sent']\n",
        "\n",
        "    # Sort the results for clarity\n",
        "    balance_df = balance_df.sort_values(by=['year_month', 'Balance'], ascending=[True, False]).reset_index(drop=True)\n",
        "\n",
        "    print(f\"[INFO] Calculated balances snapshot for {balance_df['year_month'].nunique()} months and {len(balance_df)} address-month pairs.\")\n",
        "    return balance_df\n",
        "\n",
        "\n",
        "def transform_block_time(df, time_column='Block Time'):\n",
        "    \"\"\"\n",
        "    Transform 'Block Time' into datetime and extract year_month and year_month_day.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame with a time column.\n",
        "        time_column (str): Name of the time column.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Updated DataFrame with 'year_month' and 'year_month_day' columns.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df[time_column] = pd.to_datetime(df[time_column], errors='coerce')\n",
        "        df['year_month'] = df[time_column].dt.to_period('M').astype(str)\n",
        "        df['year_month_day'] = df[time_column].dt.strftime('%Y-%m-%d')\n",
        "        print(f\"[INFO] Transformed '{time_column}' into 'year_month' and 'year_month_day'.\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Failed to transform '{time_column}': {e}\")\n",
        "        return df\n",
        "\n",
        "# ============================\n",
        "# 3. Data Saving\n",
        "# ============================\n",
        "def save_balances(balance_df, file_path):\n",
        "    \"\"\"\n",
        "    Save balance data to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        balance_df (pd.DataFrame): DataFrame containing balance data.\n",
        "        file_path (str): Path to save the CSV file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        balance_df.to_csv(file_path, index=False)\n",
        "        print(f\"[INFO] Saved balance data to {file_path}. Total rows: {len(balance_df)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] An error occurred while saving the file: {e}\")\n",
        "\n",
        "# ============================\n",
        "# . Main Function\n",
        "# ============================\n",
        "def main():\n",
        "    # Example data\n",
        "    data_names = [\n",
        "        FLOKI_data,\n",
        "        Bonk_data,\n",
        "        Mog_data,\n",
        "        Shib_data,\n",
        "        Pepe_data\n",
        "    ]\n",
        "\n",
        "    directory_path = [\n",
        "        'data/Floki',\n",
        "        'data/Bonk',\n",
        "        'data/Mog',\n",
        "        'data/Shib',\n",
        "        'data/Pepe'\n",
        "    ]\n",
        "\n",
        "    # Load and combine data\n",
        "    for data, trans_path in zip(data_names, directory_path):\n",
        "        # Calculate balances\n",
        "        balance_df = calculate_balances(data)\n",
        "        # Save balances\n",
        "        save_balances(balance_df, f'transform_data/{trans_path[5:]}_token_balances.csv')\n",
        "\n",
        "# ============================\n",
        "# Entry Point\n",
        "# ============================\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47bf531b-7400-41dc-84fa-255cabc297b0",
      "metadata": {
        "id": "47bf531b-7400-41dc-84fa-255cabc297b0",
        "outputId": "9764b945-a91b-4b47-c021-7b1d2a4584c3",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Loaded data from transform_data/Flokitoken_balances.csv: 335829 rows, 5 columns.\n",
            "[INFO] Preprocessed data: 180250 valid rows remaining.\n",
            "[INFO] Plot saved: plots\\Balance long tail(year_month)_Combined_token.png\n",
            "[INFO] Plot saved: plots\\Balance long tail(half_year)_Combined_token.png\n",
            "[INFO] Plot saved: plots\\Balance long tail(year)_Combined_token.png\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# ============================\n",
        "# 1. Load Balance Data\n",
        "# ============================\n",
        "def load_balance_data(file_path):\n",
        "    \"\"\"\n",
        "    Load and preprocess balance data from a CSV or Excel file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the balance data file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Cleaned and preprocessed DataFrame with 'year_month', 'Address', and 'Balance' columns.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"[ERROR] The file '{file_path}' does not exist.\")\n",
        "\n",
        "    try:\n",
        "        # Load data based on file extension\n",
        "        if file_path.endswith('.csv'):\n",
        "            balance_df = pd.read_csv(file_path)\n",
        "        elif file_path.endswith(('.xls', '.xlsx')):\n",
        "            balance_df = pd.read_excel(file_path)\n",
        "        else:\n",
        "            raise ValueError(\"[ERROR] Unsupported file format. Use CSV or Excel files.\")\n",
        "\n",
        "        print(f\"[INFO] Loaded data from {file_path}: {balance_df.shape[0]} rows, {balance_df.shape[1]} columns.\")\n",
        "\n",
        "        # Ensure required columns exist\n",
        "        required_columns = {'year_month', 'Address', 'Balance'}\n",
        "        if not required_columns.issubset(balance_df.columns):\n",
        "            raise ValueError(f\"[ERROR] File must contain the following columns: {required_columns}\")\n",
        "\n",
        "        # Ensure 'year_month' is a string\n",
        "        balance_df['year_month'] = balance_df['year_month'].astype(str)\n",
        "\n",
        "        # Ensure 'Balance' is numeric\n",
        "        balance_df['Balance'] = pd.to_numeric(balance_df['Balance'], errors='coerce').fillna(0)\n",
        "\n",
        "        # Remove invalid or zero balances\n",
        "        balance_df = balance_df[balance_df['Balance'] > 0]\n",
        "\n",
        "        # Sort data for clarity\n",
        "        balance_df = balance_df.sort_values(by=['year_month', 'Balance'], ascending=[True, False]).reset_index(drop=True)\n",
        "\n",
        "        print(f\"[INFO] Preprocessed data: {balance_df.shape[0]} valid rows remaining.\")\n",
        "        return balance_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Failed to load and preprocess data: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# ============================\n",
        "# 2. Plot Token Distribution by Year-Month\n",
        "# ============================\n",
        "def plot_all_token_snapshots(balance_df):\n",
        "    \"\"\"\n",
        "    Plot token balance distributions for all year_month snapshots in one plot.\n",
        "\n",
        "    Args:\n",
        "        balance_df (pd.DataFrame): DataFrame with 'year_month', 'Address', and 'Balance'.\n",
        "    \"\"\"\n",
        "    # Ensure required columns exist\n",
        "    required_columns = {'year_month', 'Address', 'Balance'}\n",
        "    if not required_columns.issubset(balance_df.columns):\n",
        "        raise ValueError(f\"[ERROR] DataFrame must contain the following columns: {required_columns}\")\n",
        "\n",
        "    # Get unique year_month values\n",
        "    available_months = sorted(balance_df['year_month'].unique())\n",
        "\n",
        "    # Define color palette\n",
        "    colors = plt.cm.tab20(np.linspace(0, 1, len(available_months)))\n",
        "\n",
        "    plt.figure(figsize=(14, 8))\n",
        "\n",
        "    for i, month in enumerate(available_months):\n",
        "        filtered_df = balance_df[balance_df['year_month'] == month]\n",
        "\n",
        "        if filtered_df.empty:\n",
        "            print(f\"[WARNING] No data available for {month}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Plot histogram for each month\n",
        "        plt.hist(\n",
        "            filtered_df['Balance'],\n",
        "            bins=50,\n",
        "            alpha=0.5,\n",
        "            label=f'{month}',\n",
        "            color=colors[i],\n",
        "            log=True\n",
        "        )\n",
        "\n",
        "    plt.title('Token Balance Distribution Across Year-Month Snapshots')\n",
        "    plt.xlabel('Token Balance (Log Scale)')\n",
        "    plt.ylabel('Number of Addresses')\n",
        "    plt.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0), fontsize='small')\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_plot('Balance long tail(year_month)', 'Combined_token')\n",
        "    plt.show()\n",
        "\n",
        "def plot_half_year_token_snapshots(balance_df):\n",
        "    \"\"\"\n",
        "    Plot token balance distributions for half-year snapshots in one plot.\n",
        "\n",
        "    Args:\n",
        "        balance_df (pd.DataFrame): DataFrame with 'year_month', 'Address', and 'Balance'.\n",
        "    \"\"\"\n",
        "    # Ensure required columns exist\n",
        "    required_columns = {'year_month', 'Address', 'Balance'}\n",
        "    if not required_columns.issubset(balance_df.columns):\n",
        "        raise ValueError(f\"[ERROR] DataFrame must contain the following columns: {required_columns}\")\n",
        "\n",
        "    # Ensure 'year_month' is datetime for easier manipulation\n",
        "    balance_df['year_month'] = pd.to_datetime(balance_df['year_month'], format='%Y-%m')\n",
        "\n",
        "    # Create half-year column\n",
        "    balance_df['half_year'] = balance_df['year_month'].dt.year.astype(str) + \\\n",
        "                              '-H' + ((balance_df['year_month'].dt.month - 1) // 6 + 1).astype(str)\n",
        "\n",
        "    # Get unique half-year values\n",
        "    available_half_years = sorted(balance_df['half_year'].unique())\n",
        "\n",
        "    # Define color palette\n",
        "    colors = plt.cm.tab20(np.linspace(0, 1, len(available_half_years)))\n",
        "\n",
        "    plt.figure(figsize=(14, 8))\n",
        "\n",
        "    for i, half_year in enumerate(available_half_years):\n",
        "        filtered_df = balance_df[balance_df['half_year'] == half_year]\n",
        "\n",
        "        if filtered_df.empty:\n",
        "            print(f\"[WARNING] No data available for {half_year}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Plot histogram for each half-year\n",
        "        plt.hist(\n",
        "            filtered_df['Balance'],\n",
        "            bins=50,\n",
        "            alpha=0.5,\n",
        "            label=f'{half_year}',\n",
        "            color=colors[i],\n",
        "            log=True\n",
        "        )\n",
        "\n",
        "    plt.title('Token Balance Distribution Across Half-Year Snapshots')\n",
        "    plt.xlabel('Token Balance (Log Scale)')\n",
        "    plt.ylabel('Number of Addresses')\n",
        "    plt.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0), fontsize='small')\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_plot('Balance long tail(half_year)', 'Combined_token')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_yearly_token_snapshots(balance_df):\n",
        "    \"\"\"\n",
        "    Plot token balance distributions for yearly snapshots in one plot.\n",
        "\n",
        "    Args:\n",
        "        balance_df (pd.DataFrame): DataFrame with 'year_month', 'Address', and 'Balance'.\n",
        "    \"\"\"\n",
        "    # Ensure required columns exist\n",
        "    required_columns = {'year_month', 'Address', 'Balance'}\n",
        "    if not required_columns.issubset(balance_df.columns):\n",
        "        raise ValueError(f\"[ERROR] DataFrame must contain the following columns: {required_columns}\")\n",
        "\n",
        "    # Ensure 'year_month' is datetime for easier manipulation\n",
        "    balance_df['year_month'] = pd.to_datetime(balance_df['year_month'], format='%Y-%m')\n",
        "\n",
        "    # Create a 'year' column\n",
        "    balance_df['year'] = balance_df['year_month'].dt.year.astype(str)\n",
        "\n",
        "    # Get unique years\n",
        "    available_years = sorted(balance_df['year'].unique())\n",
        "\n",
        "    # Define color palette\n",
        "    colors = plt.cm.tab20(np.linspace(0, 1, len(available_years)))\n",
        "\n",
        "    # Plot setup\n",
        "    plt.figure(figsize=(14, 8))\n",
        "\n",
        "    for i, year in enumerate(available_years):\n",
        "        filtered_df = balance_df[balance_df['year'] == year]\n",
        "\n",
        "        if filtered_df.empty:\n",
        "            print(f\"[WARNING] No data available for {year}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Plot histogram for each year\n",
        "        plt.hist(\n",
        "            filtered_df['Balance'],\n",
        "            bins=50,\n",
        "            alpha=0.5,\n",
        "            label=f'{year}',\n",
        "            color=colors[i],\n",
        "            log=True\n",
        "        )\n",
        "\n",
        "    # 📊 Titles and Labels\n",
        "    plt.title('Token Balance Distribution Across Yearly Snapshots')\n",
        "    plt.xlabel('Token Balance (Log Scale)')\n",
        "    plt.ylabel('Number of Addresses')\n",
        "    plt.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0), fontsize='small')\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_plot('Balance long tail(year)', 'Combined_token')\n",
        "    # Show Plot\n",
        "    plt.show()\n",
        "\n",
        "# ============================\n",
        "# 3. Save Plots\n",
        "# ============================\n",
        "def save_plot(file_name, plot_type, output_dir='plots'):\n",
        "    \"\"\"\n",
        "    Save the current plot to a specified directory.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    plot_file_name = f\"{file_name}_{plot_type}.png\"\n",
        "    plot_path = os.path.join(output_dir, plot_file_name)\n",
        "    plt.savefig(plot_path, bbox_inches='tight')\n",
        "    print(f\"[INFO] Plot saved: {plot_path}\")\n",
        "    plt.close()\n",
        "\n",
        "# ============================\n",
        "# . Main Function\n",
        "# ============================\n",
        "def main():\n",
        "   # Define file paths and patterns\n",
        "    directory_path = 'transform_data'\n",
        "    file_names = [\n",
        "        'Floki_token_balances.csv',\n",
        "        'Bonk_token_balances.csv',\n",
        "        'Mog_token_balances.csv',\n",
        "        'Shib_token_balances.csv',\n",
        "        'Pepe_token_balances.csv'\n",
        "    ]\n",
        "    token_names = ['FLOKI', 'BONK', 'MOG', 'SHIB', 'PEPE']\n",
        "    #token_names = ['FLOKI', 'BONK', 'MOG', 'PEPE']\n",
        "\n",
        "    # Plot Token Distribution\n",
        "    if not balance_df.empty:\n",
        "        plot_all_token_snapshots(balance_df)\n",
        "        plot_half_year_token_snapshots(balance_df)\n",
        "        plot_yearly_token_snapshots(balance_df)\n",
        "    else:\n",
        "        print(\"[ERROR] No data available for plotting.\")\n",
        "\n",
        "# ============================\n",
        "# Entry Point\n",
        "# ============================\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
