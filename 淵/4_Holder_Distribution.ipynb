{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6261421",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.oauth2 import service_account\n",
        "from google.cloud import bigquery\n",
        "from google.cloud.exceptions import NotFound\n",
        "import pandas as pd\n",
        "from google.cloud import storage\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dadfef97",
      "metadata": {},
      "outputs": [],
      "source": [
        "project_id = \"looker-assignment-113356033\"\n",
        "dataset_id = \"final_project_dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "583fb109",
      "metadata": {},
      "outputs": [],
      "source": [
        "crendentials = service_account.Credentials.from_service_account_file(r\"C:\\nccu\\workspace\\dataModel_finalProjrct\\looker-assignment-113356033-4959799503ac.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baa1366c",
      "metadata": {},
      "outputs": [],
      "source": [
        "bigquery_client = bigquery.Client(project=project_id, credentials=crendentials)\n",
        "storage_client = storage.Client(credentials=crendentials, project=project_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ee01363-3400-41ec-aac6-611689f45206",
      "metadata": {
        "id": "3ee01363-3400-41ec-aac6-611689f45206"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# 1. Data Loading and Cleaning\n",
        "# ============================\n",
        "def load_and_clean_data(balance_df):\n",
        "    \"\"\"\n",
        "    Preprocess token holder data from a DataFrame.\n",
        "    \"\"\"\n",
        "    # Remove commas and convert Balance column to numeric\n",
        "    balance_df['Balance'] = balance_df['Balance'].str.replace(',', '', regex=True)\n",
        "    balance_df['Balance'] = pd.to_numeric(balance_df['Balance'], errors='coerce')\n",
        "\n",
        "    # Create \"Percentage\" column\n",
        "    total_balance = balance_df['Balance'].sum()\n",
        "    balance_df['Percentage'] = (balance_df['Balance'] / total_balance) * 100\n",
        "\n",
        "    print(f\"[INFO] Data cleaned: {balance_df.shape[0]} rows, {balance_df.shape[1]} columns\")\n",
        "    return balance_df\n",
        "\n",
        "# ============================\n",
        "# 2. Plot Long-tail Distribution\n",
        "# ============================\n",
        "def plot_long_tail_distribution(balance_df, balance_column, title):\n",
        "    \"\"\"\n",
        "    Plot the long-tail distribution of holder balances on a log scale.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.hist(np.log10(balance_df[balance_column]), bins=100, edgecolor='black', alpha=0.7)\n",
        "    plt.title(f'Distribution of Holder Balances (Log-Scale) - {title}')\n",
        "    plt.xlabel('Log10(Balance)')\n",
        "    plt.ylabel('Number of Holders')\n",
        "    plt.show()\n",
        "\n",
        "def plot_combined_long_tail_distribution(file_data_dict):\n",
        "    \"\"\"\n",
        "    Plot the long-tail distribution for multiple datasets on the same plot using histograms.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot each dataset as a histogram\n",
        "    for file_name, df in file_data_dict.items():\n",
        "        # Ensure no NaN or invalid values\n",
        "        df = df.dropna(subset=['Balance'])\n",
        "        df = df[df['Balance'] > 0]\n",
        "\n",
        "        # Calculate Log10(Balance)\n",
        "        log_balance = np.log10(df['Balance'])\n",
        "\n",
        "        # Plot histogram\n",
        "        plt.hist(\n",
        "            log_balance,\n",
        "            bins=100,\n",
        "            alpha=0.5,\n",
        "            label=file_name,\n",
        "            edgecolor='black'\n",
        "        )\n",
        "\n",
        "    # Add plot details\n",
        "    plt.title('Combined Long-Tail Distribution of Holder Balances (Log-Scale)')\n",
        "    plt.xlabel('Log10(Balance)')\n",
        "    plt.ylabel('Number of Holders')\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.show()\n",
        "\n",
        "# ============================\n",
        "# 3. Plot Cumulative Distribution Function (CDF) by Log10(Balance)\n",
        "# ============================\n",
        "def plot_cdf_by_log_balance(balance_df, balance_column, title):\n",
        "    \"\"\"\n",
        "    Plot the cumulative distribution function (CDF) using Log10(Balance).\n",
        "    \"\"\"\n",
        "    balance_df['log_balance'] = np.log10(balance_df[balance_column])\n",
        "    df_sorted = balance_df.sort_values(by='log_balance', ascending=True)\n",
        "    df_sorted['cumulative_percentage'] = df_sorted['Balance'].cumsum() / df_sorted['Balance'].sum() * 100\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(df_sorted['log_balance'], df_sorted['cumulative_percentage'], marker='o', linestyle='-')\n",
        "    plt.title(f'Cumulative Distribution of Holder Balances - {title}')\n",
        "    plt.xlabel('Log10(Balance)')\n",
        "    plt.ylabel('Cumulative Percentage (%)')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def plot_combined_cdf_by_log_balance(file_data_dict):\n",
        "    \"\"\"\n",
        "    Plot the cumulative distribution function (CDF) for multiple datasets on the same plot.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    for file_name, df in file_data_dict.items():\n",
        "        df['log_balance'] = np.log10(df['Balance'])\n",
        "        df_sorted = df.sort_values(by='log_balance')\n",
        "        df_sorted['cumulative_percentage'] = df_sorted['Balance'].cumsum() / df_sorted['Balance'].sum() * 100\n",
        "\n",
        "        plt.plot(df_sorted['log_balance'], df_sorted['cumulative_percentage'],\n",
        "                 marker='o', linestyle='-', label=file_name)\n",
        "\n",
        "    plt.title('Combined CDF of Holder Balances (Log10(Balance))')\n",
        "    plt.xlabel('Log10(Balance)')\n",
        "    plt.ylabel('Cumulative Percentage (%)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.show()\n",
        "\n",
        "# ============================\n",
        "# 4. Plot CDF with Address Index\n",
        "# ============================\n",
        "def plot_cdf_by_index(balance_df, title):\n",
        "    \"\"\"\n",
        "    Plot the cumulative distribution function (CDF) using Address Index.\n",
        "    \"\"\"\n",
        "    balance_df = balance_df.sort_values(by='Balance', ascending=True).reset_index(drop=True)\n",
        "    balance_df['cumulative_percentage'] = balance_df['Balance'].cumsum() / balance_df['Balance'].sum() * 100\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(balance_df.index, balance_df['cumulative_percentage'], marker='o', linestyle='-')\n",
        "    plt.title(f'Cumulative Distribution of Holder Balances by Index - {title}')\n",
        "    plt.xlabel('Address Index')\n",
        "    plt.ylabel('Cumulative Percentage (%)')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def plot_combined_cdf_by_index(file_data_dict):\n",
        "    \"\"\"\n",
        "    Plot the cumulative distribution function (CDF) by Address Index for multiple datasets.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    for file_name, df in file_data_dict.items():\n",
        "        df_sorted = df.sort_values(by='Balance').reset_index(drop=True)\n",
        "        df_sorted['cumulative_percentage'] = df_sorted['Balance'].cumsum() / df_sorted['Balance'].sum() * 100\n",
        "\n",
        "        plt.plot(df_sorted.index, df_sorted['cumulative_percentage'],\n",
        "                 marker='o', linestyle='-', label=file_name)\n",
        "\n",
        "    plt.title('Combined CDF of Holder Balances by Address Index')\n",
        "    plt.xlabel('Address Index')\n",
        "    plt.ylabel('Cumulative Percentage (%)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.show()\n",
        "\n",
        "# ============================\n",
        "# 5. Process Multiple Files\n",
        "# ============================\n",
        "def process_multiple_files(data_frames):\n",
        "    \"\"\"\n",
        "    Process and visualize multiple token holder datasets.\n",
        "    \"\"\"\n",
        "    for idx, balance_df in enumerate(data_frames):\n",
        "        try:\n",
        "            title = f\"Dataset {idx + 1}\"\n",
        "\n",
        "            # Clean data\n",
        "            balance_df = load_and_clean_data(balance_df)\n",
        "\n",
        "            # Define balance column\n",
        "            balance_column = 'Balance'\n",
        "\n",
        "            # Generate plots\n",
        "            plot_long_tail_distribution(balance_df, balance_column, title)\n",
        "            plot_cdf_by_log_balance(balance_df, balance_column, title)\n",
        "            plot_cdf_by_index(balance_df, title)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] Failed to process dataset {idx + 1}: {e}\")\n",
        "\n",
        "def process_combined_multiple_files(data_frames):\n",
        "    \"\"\"\n",
        "    Process multiple token holder datasets and generate combined plots.\n",
        "    \"\"\"\n",
        "    file_data_dict = {}\n",
        "\n",
        "    for idx, balance_df in enumerate(data_frames):\n",
        "        try:\n",
        "            title = f\"Dataset {idx + 1}\"\n",
        "            balance_df = load_and_clean_data(balance_df)\n",
        "            file_data_dict[title] = balance_df\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] Failed to process dataset {idx + 1}: {e}\")\n",
        "\n",
        "    # Plot combined visualizations\n",
        "    if file_data_dict:\n",
        "        plot_combined_long_tail_distribution(file_data_dict)\n",
        "        plot_combined_cdf_by_log_balance(file_data_dict)\n",
        "        plot_combined_cdf_by_index(file_data_dict)\n",
        "\n",
        "# ============================\n",
        "# 6. Main Function\n",
        "# ============================\n",
        "def main():\n",
        "    # Query token holder data\n",
        "    Bonk_query = \"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM `looker-assignment-113356033.final_project_dataset.Bonk_top200_holders`\n",
        "    \"\"\"\n",
        "    Bonk_holders_data = bigquery_client.query(Bonk_query).to_dataframe()\n",
        "\n",
        "    FLOKI_query = \"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM `looker-assignment-113356033.final_project_dataset.FLOKI_top200_holders`\n",
        "    \"\"\"\n",
        "    FLOKI_holders_data = bigquery_client.query(FLOKI_query).to_dataframe()\n",
        "\n",
        "    Mog_query = \"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM `looker-assignment-113356033.final_project_dataset.Mog_top200_holders`\n",
        "    \"\"\"\n",
        "    Mog_holders_data = bigquery_client.query(Mog_query).to_dataframe()\n",
        "\n",
        "    Pepe_query = \"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM `looker-assignment-113356033.final_project_dataset.Pepe_top200_holders`\n",
        "    \"\"\"\n",
        "    Pepe_holders_data = bigquery_client.query(Pepe_query).to_dataframe()\n",
        "\n",
        "    Shib_query = \"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM `looker-assignment-113356033.final_project_dataset.Shib_top200_holders`\n",
        "    \"\"\"\n",
        "    Shib_holders_data = bigquery_client.query(Shib_query).to_dataframe()\n",
        "\n",
        "    holder_data = [\n",
        "        Bonk_holders_data,\n",
        "        FLOKI_holders_data,\n",
        "        Mog_holders_data,\n",
        "        Pepe_holders_data,\n",
        "        Shib_holders_data\n",
        "    ]\n",
        "\n",
        "    # Process datasets\n",
        "    process_combined_multiple_files(holder_data)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecbe1b93-b479-439e-83d8-72c92981f8e9",
      "metadata": {
        "id": "ecbe1b93-b479-439e-83d8-72c92981f8e9",
        "outputId": "51e96df2-cf9e-4af6-bae4-1a8bcc8e1801"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Data loaded and cleaned from data/top_200_bonk_top_holders.csv: 200 rows, 4 columns\n",
            "[INFO] Data loaded and cleaned from data/top_200_floki_top_holders.csv: 200 rows, 4 columns\n",
            "[INFO] Data loaded and cleaned from data/top_200_mog_top_holders.csv: 200 rows, 4 columns\n",
            "[INFO] Data loaded and cleaned from data/top_200_pepe_top_holders.csv: 200 rows, 4 columns\n",
            "[INFO] Data loaded and cleaned from data/top_200_shib_top_holders.csv: 200 rows, 4 columns\n",
            "[INFO] Plot saved: plots\\long_tail.png\n",
            "[INFO] Plot saved: plots\\cdf_log_balance.png\n",
            "[INFO] Plot saved: plots\\cdf_index.png\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# Entry Point\n",
        "# ============================\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c16baa18-6781-48e3-9d52-4dd916e248b1",
      "metadata": {
        "id": "c16baa18-6781-48e3-9d52-4dd916e248b1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_balance_percentage(df):\n",
        "    \"\"\"\n",
        "    Calculate the balance percentage for a given DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Input DataFrame containing 'Balance Amount'.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with an additional 'Balance percentage' column.\n",
        "    \"\"\"\n",
        "    # Ensure 'Balance Amount' is numeric\n",
        "    df['Balance Amount'] = pd.to_numeric(\n",
        "        df['Balance Amount'].astype(str).str.replace(',', '', regex=True),\n",
        "        errors='coerce'\n",
        "    )\n",
        "\n",
        "    # Drop rows with invalid 'Balance Amount'\n",
        "    df = df.dropna(subset=['Balance Amount'])\n",
        "\n",
        "    # Calculate 'Balance percentage'\n",
        "    total_balance = df['Balance Amount'].sum()\n",
        "    if total_balance > 0:\n",
        "        df['Balance percentage'] = (df['Balance Amount'] / total_balance) * 100\n",
        "    else:\n",
        "        df['Balance percentage'] = 0.0\n",
        "\n",
        "    return df\n",
        "\n",
        "def plot_combined_long_tail_distribution(holders_data, names):\n",
        "    \"\"\"\n",
        "    Plot the combined long-tail distribution for multiple datasets.\n",
        "\n",
        "    Args:\n",
        "        holders_data (list of pd.DataFrame): List of DataFrames containing holder data.\n",
        "        names (list of str): List of dataset names for labeling.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    for df, name in zip(holders_data, names):\n",
        "        # Calculate balance percentage\n",
        "        df = calculate_balance_percentage(df)\n",
        "\n",
        "        # Remove invalid data\n",
        "        df = df[df['Balance percentage'] > 0]\n",
        "\n",
        "        # Avoid log(0) by adding a small constant\n",
        "        df['Adjusted Percentage'] = df['Balance percentage'] + 1e-6\n",
        "\n",
        "        # Calculate normalized weights\n",
        "        weights = np.ones(len(df['Adjusted Percentage'])) / len(df['Adjusted Percentage'])\n",
        "\n",
        "        # Plot histogram\n",
        "        plt.hist(\n",
        "            df['Adjusted Percentage'],\n",
        "            bins=np.logspace(\n",
        "                np.log10(df['Adjusted Percentage'].min()),\n",
        "                np.log10(df['Adjusted Percentage'].max()),\n",
        "                100\n",
        "            ),\n",
        "            weights=weights,\n",
        "            alpha=0.5,\n",
        "            label=name,\n",
        "            edgecolor='black'\n",
        "        )\n",
        "\n",
        "    # Set log scale for the x-axis\n",
        "    plt.xscale('log')\n",
        "\n",
        "    # Add title and labels\n",
        "    plt.title('Combined Long-Tail Distribution of Holder Percentages (Normalized Y-axis)')\n",
        "    plt.xlabel('Balance Percentage (Log Scale)')\n",
        "    plt.ylabel('Proportion of Holders')\n",
        "    plt.legend()\n",
        "    plt.grid(True, which='both', linestyle='--', alpha=0.5)\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "\n",
        "def main():\n",
        "    # Example data\n",
        "    Bonk_query = \"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM `looker-assignment-113356033.final_project_dataset.Bonk_holders`\n",
        "    \"\"\"\n",
        "    Bonk_holders_data = bigquery_client.query(Bonk_query).to_dataframe()\n",
        "\n",
        "    FLOKI_query = \"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM `looker-assignment-113356033.final_project_dataset.FLOKI_holders`\n",
        "    \"\"\"\n",
        "    FLOKI_holders_data = bigquery_client.query(FLOKI_query).to_dataframe()\n",
        "\n",
        "    Mog_query = \"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM `looker-assignment-113356033.final_project_dataset.Mog_holders`\n",
        "    \"\"\"\n",
        "    Mog_holders_data = bigquery_client.query(Mog_query).to_dataframe()\n",
        "\n",
        "    Pepe_query = \"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM `looker-assignment-113356033.final_project_dataset.Pepe_holders`\n",
        "    \"\"\"\n",
        "    Pepe_holders_data = bigquery_client.query(Pepe_query).to_dataframe()\n",
        "\n",
        "    Shib_query = \"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM `looker-assignment-113356033.final_project_dataset.Shib_holders`\n",
        "    \"\"\"\n",
        "    Shib_holders_data = bigquery_client.query(Shib_query).to_dataframe()\n",
        "\n",
        "    holders_data = [\n",
        "        Bonk_holders_data,\n",
        "        FLOKI_holders_data,\n",
        "        Mog_holders_data,\n",
        "        Pepe_holders_data,\n",
        "        Shib_holders_data\n",
        "    ]\n",
        "\n",
        "    dataset_names = ['Bonk', 'FLOKI', 'Mog', 'Pepe', 'Shib']\n",
        "\n",
        "    # Plot combined long-tail distribution\n",
        "    plot_combined_long_tail_distribution(holders_data, dataset_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cc971db-7c11-410d-98f7-c44904027a5f",
      "metadata": {
        "id": "5cc971db-7c11-410d-98f7-c44904027a5f",
        "outputId": "8f6c5f53-89ec-4169-fbc6-76e9b10c4152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Found 1 files. Loading...\n",
            "[INFO] Loaded data/token_holders/all\\floki_token_holders.xlsx with 88432 rows and 6 columns.\n",
            "[INFO] Combined DataFrame shape: (88432, 6)\n",
            "[INFO] Found 1 files. Loading...\n",
            "[INFO] Loaded data/token_holders/all\\bonk_token_holders.xlsx with 14105 rows and 6 columns.\n",
            "[INFO] Combined DataFrame shape: (14105, 6)\n",
            "[INFO] Found 1 files. Loading...\n",
            "[INFO] Loaded data/token_holders/all\\mog_token_holders.xlsx with 48424 rows and 6 columns.\n",
            "[INFO] Combined DataFrame shape: (48424, 6)\n",
            "[INFO] Found 15 files. Loading...\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part1.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part10.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part11.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part12.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part13.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part14.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part15.xlsx with 81339 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part2.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part3.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part4.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part5.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part6.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part7.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part8.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part9.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Combined DataFrame shape: (1481339, 6)\n",
            "[INFO] Found 4 files. Loading...\n",
            "[INFO] Loaded data/token_holders/all\\PEPE_token_holders_part1.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\PEPE_token_holders_part2.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\PEPE_token_holders_part3.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\PEPE_token_holders_part4.xlsx with 65009 rows and 6 columns.\n",
            "[INFO] Combined DataFrame shape: (365009, 6)\n",
            "[INFO] Plot saved: plots\\long_tail_percentage.png\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# Entry Point\n",
        "# ============================\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d90b47-dc6d-45d3-8009-cab44fa360aa",
      "metadata": {
        "id": "e6d90b47-dc6d-45d3-8009-cab44fa360aa",
        "outputId": "e996cf09-b2dd-4edd-e130-9a9cfc9b380e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Found 1 files. Loading...\n",
            "[INFO] Loaded data/token_holders/all\\floki_token_holders.xlsx with 88432 rows and 6 columns.\n",
            "[INFO] Combined DataFrame shape: (88432, 6)\n",
            "[INFO] Found 1 files. Loading...\n",
            "[INFO] Loaded data/token_holders/all\\bonk_token_holders.xlsx with 14105 rows and 6 columns.\n",
            "[INFO] Combined DataFrame shape: (14105, 6)\n",
            "[INFO] Found 1 files. Loading...\n",
            "[INFO] Loaded data/token_holders/all\\mog_token_holders.xlsx with 48424 rows and 6 columns.\n",
            "[INFO] Combined DataFrame shape: (48424, 6)\n",
            "[INFO] Found 15 files. Loading...\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part1.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part10.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part11.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part12.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part13.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part14.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part15.xlsx with 81339 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part2.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part3.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part4.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part5.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part6.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part7.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part8.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\SHIB_token_holders_part9.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Combined DataFrame shape: (1481339, 6)\n",
            "[INFO] Found 4 files. Loading...\n",
            "[INFO] Loaded data/token_holders/all\\PEPE_token_holders_part1.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\PEPE_token_holders_part2.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\PEPE_token_holders_part3.xlsx with 100000 rows and 6 columns.\n",
            "[INFO] Loaded data/token_holders/all\\PEPE_token_holders_part4.xlsx with 65009 rows and 6 columns.\n",
            "[INFO] Combined DataFrame shape: (365009, 6)\n"
          ]
        }
      ],
      "source": [
        "# Example: Load data from BigQuery and process\n",
        "file_data_dict = {}\n",
        "\n",
        "# Queries for each token holder dataset\n",
        "queries = {\n",
        "    \"floki\": \"\"\"\n",
        "        SELECT * \n",
        "        FROM `looker-assignment-113356033.final_project_dataset.FLOKI_holders`\n",
        "    \"\"\",\n",
        "    \"bonk\": \"\"\"\n",
        "        SELECT * \n",
        "        FROM `looker-assignment-113356033.final_project_dataset.Bonk_holders`\n",
        "    \"\"\",\n",
        "    \"mog\": \"\"\"\n",
        "        SELECT * \n",
        "        FROM `looker-assignment-113356033.final_project_dataset.Mog_holders`\n",
        "    \"\"\",\n",
        "    \"shib\": \"\"\"\n",
        "        SELECT * \n",
        "        FROM `looker-assignment-113356033.final_project_dataset.Shib_holders`\n",
        "    \"\"\",\n",
        "    \"pepe\": \"\"\"\n",
        "        SELECT * \n",
        "        FROM `looker-assignment-113356033.final_project_dataset.Pepe_holders`\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "# Load data for each token holder and store in the dictionary\n",
        "for token_name, query in queries.items():\n",
        "    try:\n",
        "        # Execute the query and load data into a DataFrame\n",
        "        df = bigquery_client.query(query).to_dataframe()\n",
        "\n",
        "        # Ensure 'Balance Amount' is numeric\n",
        "        df['Balance Amount'] = pd.to_numeric(\n",
        "            df['Balance Amount'].astype(str).str.replace(',', '', regex=True),\n",
        "            errors='coerce'\n",
        "        )\n",
        "        \n",
        "        # Drop rows with missing or invalid 'Balance Amount'\n",
        "        df = df.dropna(subset=['Balance Amount'])\n",
        "\n",
        "        # Calculate 'Balance percentage'\n",
        "        total_balance = df['Balance Amount'].sum()\n",
        "        if total_balance > 0:\n",
        "            df['Balance percentage'] = (df['Balance Amount'] / total_balance) * 100\n",
        "        else:\n",
        "            df['Balance percentage'] = 0.0\n",
        "\n",
        "        # Add the processed DataFrame to the dictionary\n",
        "        file_data_dict[token_name] = df\n",
        "        print(f\"[INFO] Loaded and processed data for {token_name} with {df.shape[0]} rows.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Failed to load data for {token_name}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5fba865-6528-4ca6-abde-dfdd7076d3d5",
      "metadata": {
        "id": "a5fba865-6528-4ca6-abde-dfdd7076d3d5",
        "outputId": "ddef50dd-6994-410d-e33c-04a263bcfb8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Plot saved: plots\\floki_long_tail_percentage_log.png\n",
            "[INFO] Plot saved: plots\\bonk_long_tail_percentage_log.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\JIN\\AppData\\Local\\Temp\\ipykernel_456016\\4007907391.py:88: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  balance_df['Adjusted Percentage'] = balance_df[percentage_column] + 1e-6  # 避免 log(0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Plot saved: plots\\mog_long_tail_percentage_log.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\JIN\\AppData\\Local\\Temp\\ipykernel_456016\\4007907391.py:88: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  balance_df['Adjusted Percentage'] = balance_df[percentage_column] + 1e-6  # 避免 log(0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Plot saved: plots\\SHIB_long_tail_percentage_log.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\JIN\\AppData\\Local\\Temp\\ipykernel_456016\\4007907391.py:88: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  balance_df['Adjusted Percentage'] = balance_df[percentage_column] + 1e-6  # 避免 log(0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Plot saved: plots\\PEPE_long_tail_percentage_log.png\n"
          ]
        }
      ],
      "source": [
        "for file_name, df in file_data_dict.items():\n",
        "    plot_long_tail_distribution(df, \"Balance percentage\", file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21c4e7fa-2923-498d-b449-545ed9750fe1",
      "metadata": {
        "id": "21c4e7fa-2923-498d-b449-545ed9750fe1",
        "outputId": "50f24b93-8d9d-4117-eda0-c30ad656ce2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Plot saved: plots\\combined_long_tail_percentage_normalized_long_tail_percentage_normalized.png\n"
          ]
        }
      ],
      "source": [
        "plot_combined_long_tail_distribution(file_data_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee281b68-45f1-45d9-8e26-48c185eb5b89",
      "metadata": {
        "id": "ee281b68-45f1-45d9-8e26-48c185eb5b89"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
